# Обязательные задания
- Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?
  ## Ответ:
  - CPU utilization: Следить за использованием процессора, поскольку вычисления загружают ЦПУ.
  - HTTP response time: Оценка времени, требуемого для обработки HTTP-запросов, чтобы понимать производительность платформы
  - Disk space: Для контроля за сохраняемыми отчетами на диске и предотвращения возможных проблем с заполнением диска.
  - HTTP error rates: Отслеживание частоты возникновения ошибок HTTP может помочь выявить проблемы в обработке запросов.
- Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?
  ## Ответ:
  - RAM (Random Access Memory): Объем оперативной памяти, используемой системой
  - Inodes: Количество индексных узлов в файловой системе, что важно для отслеживания использования файловых ресурсов
  - CPU Load Average (CPUla): Средняя загрузка процессора за определенный период времени
- Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?
  ## Ответ:
  - Использование легковесных инструментов логирования в коде (например, print() в Python)
  - Централизованное хранение внутренних логов на сервере разработки, если не удается построить полноценную систему логирования
  - Использование сервисов мониторинга ошибок (error monitoring services): Разверните инструменты, такие как Sentry, чтобы автоматически собирать и отслеживать ошибки в приложении. Эти инструменты могут предоставить подробные отчеты о каждой ошибке
- Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?
  ## Ответ:
  - Ошибка в SLA мониторинге: Ошибка скорее всего в формуле вычисления SLA. Она должна быть следующей: summ_2xx_requests / (summ_2xx_requests + summ_5xx_requests + summ_4xx_requests).Вероятно, в формуле не учитываются 4xx запросы, что приводит к неверному расчету SLA.

- Опишите основные плюсы и минусы pull и push систем мониторинга.
- Push:
-	Плюсы: Быстрая обратная связь, возможность мгновенного реагирования.
-	Минусы: Повышенное использование ресурсов, сложность масштабирования.
-	Pull:
-	Плюсы: Эффективное использование ресурсов, легкость масштабирования.
-	Минусы: Задержка в обнаружении изменений, медленная обратная связь.

- Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?
- Prometheus - 	Push
- TICK - 	Push
- Zabbix - Pull
- VictoriaMetrics - Гибридный 	Pull/Push
- Nagios - 	Pull
- Склонируйте себе репозиторий и запустите TICK-стэк, используя технологии docker и docker-compose.
- В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (http://localhost:8888).
![1]( ) 
P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим Z, например ./data:/var/lib:Z
Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
![2]()

А где взять логин и пароль?
я попыталась сделать своего пользователя, подключилась к контейнеру, создала пользователя и пароль, но с ними тоже выходит ошибка
```
vagrant@vagrant:~/sandbox$ docker exec -it sandbox_influxdb_1 /bin/bash
root@9430492f768c:/# influx
Connected to http://localhost:8086 version 1.8.10
InfluxDB shell version: 1.8.10
> CREATE USER "vagrant" WITH PASSWORD 'vagrant' WITH ALL PRIVILEGES
>
```
-Нажмите на кнопку Add a query
-Изучите вывод интерфейса и выберите БД telegraf.autogen
-В measurments выберите cpu->host->telegraf-getting-started, а в fields выберите usage_system. Внизу появится график утилизации cpu.
-Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.
Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.

-Изучите список telegraf inputs. Добавьте в конфигурацию telegraf следующий плагин - docker:
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```
Дополнительно вам может потребоваться донастройка контейнера telegraf в docker-compose.yml дополнительного volume и режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```
- После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список measurments в веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.
- Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.
